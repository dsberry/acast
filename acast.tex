%% This is file `elsarticle-template-2-harv.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
%%
%% $Id: elsarticle-template-2-harv.tex 155 2009-10-08 05:35:05Z rishi $
%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-2-harv.tex $
%%

%%\documentclass[preprint,authoryear,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:

%% Astronomy & Computing uses 5p
%% \documentclass[final,authoryear,5p,times]{elsarticle}
\documentclass[final,authoryear,5p,times,twocolumn]{elsarticle}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
\usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

\usepackage[pdftex,pdfpagemode={UseOutlines},bookmarks,bookmarksopen,colorlinks,linkcolor={blue},citecolor={green},urlcolor={red}]{hyperref}
\usepackage{hypernat}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon (default)
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   authoryear - selects author-year citations (default)
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%   longnamesfirst  -  makes first citation full author list
%%
%% \biboptions{longnamesfirst,comma}

% \biboptions{}

\journal{Astronomy \& Computing}

%% Make single quotes look right in verbatim mode
\usepackage{upquote}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{AST: A library for modelling and manipulating coordinate systems}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\author[jac]{David S.\ Berry\corref{cor1}}
\ead{d.berry@jach.hawaii.edu}
\author[ral]{Rodney F.\ Warren-Smith}
\author[cornell,jac]{Tim Jenness}

\cortext[cor1]{Corresponding author}

\address[jac]{Joint Astronomy Centre, 660 N.\ A`oh\=ok\=u Place, Hilo, HI
  96720, USA}
\address[ral]{RAL Space, STFC Rutherford Appleton Laboratory, Harwell Oxford, Didcot, Oxfordshire OX11 0QX, UK}
\address[cornell]{Department of Astronomy, Cornell University, Ithaca,
  NY 14853, USA}

\begin{abstract}
This paper describes the Starlink AST library.
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

WCS \sep data models \sep Starlink

\end{keyword}

\end{frontmatter}

% \linenumbers

%% Journal abbreviations
\newcommand{\mnras}{Mon Not R Astron Soc}
\newcommand{\aap}{Astron Astrophys}
\newcommand{\aaps}{Astron Astrophys Supp}
\newcommand{\pasp}{Pub Astron Soc Pacific}
\newcommand{\apj}{Astrophys J}
\newcommand{\apjs}{Astrophys J Supp}
\newcommand{\qjras}{Quart J R Astron Soc}
\newcommand{\an}{Astron.\ Nach.}
\newcommand{\ijimw}{Int.\ J.\ Infrared \& Millimeter Waves}
\newcommand{\procspie}{Proc.\ SPIE}
\newcommand{\aspconf}{ASP Conf. Ser.}

%% ASCL
\newcommand{\ascl}[1]{\href{http://www.ascl.net/#1}{ascl:#1}}

%% main text
\section{Introduction}
\label{sec:intro}

The Starlink AST library \citep[][\ascl{1404.016}]{SUN211} provides a
generalised scheme for modelling, manipulating and storing inter-related
coordinate systems. Whilst written in C, it has bindings for several
other languages including Python, Java, Perl and Fortran. It has
specialised support for many of the coordinate systems and projections
commonly used to describe astronomical World Coordinate Systems (WCS),
including all those described by the FITS-WCS standard, plus various
popular distortion schemes currently in use. However, it is not limited
to WCS, and may be used in any situation requiring transformation between
different coordinate systems.

Unlike FITS-WCS, which supports only a relatively small set of prescribed
transformation recipes reflecting the coordinate transformations within
an optical telescope, AST allows arbitrarily complex transformations to be
constructed by combining simple atomic transformations in series or in
parallel. This allows a much wider range of transformations to be
described than is possible using FITS-WCS, and so can accomodate a wider
range of data storage forms without the need to re-grid the data.

AST was first released in 1997 \cite[][included in ``Twenty Years of
ADASS'' \nocite{adass20}]{1998ASPC..145...41W}. Since then it has been in
continuous use within the Starlink Software Collection (\ascl{1110.012})
and is also used by various other major astronimcal software tools such as
DS9 (\ascl{0003.002}). Interest in flexible schemes for representing
inter-related coordinate systems has increased recently\footnote{For
instance, in the discussions about possible succesors to the FITS format,
and within the Astropy project}, and so it seems an appropriate time to
review the lessons learned from AST.

This paper first presents an account of the historical issues that drove
the initial development of AST, together with the reasoning behind some
of the design decisions, and then presents an over-view of the more
important aspects of the data model used by AST.

\section{Historical Perspective}

\subsection{Initial Problems}

The first release of the AST library was in 1998
\citep{1998StarB..20....7D,1998ASPC..145...41W} but some of the
underlying concepts date from the late 1980s, when the Starlink
Project was designing its NDF data format for gridded astronomical
data \citep{2015Jenness}. There was clearly a need to relate positions
within gridded data, using coordinates based on pixel indices, to
real-world positions on the sky, wavelengths in a spectrum and so
on. These non-pixel coordinate systems are now generally known as
world coordinate systems (WCS).

Calibration of spectra, for example, was commonly performed by fitting
a polynomial to express wavelength as a function of pixel position and
then either storing the polynomial coefficients, or tabulating the
polynomial value at each pixel centre. While not completely general,
the latter option was an acceptable solution and was adopted as part
of the Starlink data format. An array giving the central wavelength at
each pixel was stored as the \texttt{AXIS} component in the NDF data
structure and did good service in spectroscopic applications. It was
also possible, in a simple minded way, to attach an \texttt{AXIS}
array to each dimension of an image or any gridded dataset of higher
dimensionality. This allowed each of its axes to be calibrated in
terms of world coordinates.

This approach was adequate if the axes represented independent
quantities (like wavelength and position for a long-slit spectrum),
but did not suffice if the axes were inter-independent. Unfortunately,
in the common case of celestial coordinates (such as Right Ascension
and Declination), the axes are almost always inter-dependent. This is
because the sky is essentially spherical and its coordinates are
therefore naturally curvilinear when projected into two
dimensions. This inter-dependence is a common feature of world
cordinate systems in practice, so a solution was clearly needed that
addressed it properly.

The Flexible Image Transport System
\citep[FITS;][]{1981A&AS...44..363W,1995ASPC...77..233G}, at that
time, addressed the issue in a better but still rudimentary way. In
essence, it stored a physical pixel size (e.g., in seconds of arc),
allowed for a linear scaling of an image (typically to allow for the
position angle rotation of the telescope) and then projected it on to
the celestial sphere using one of a defined set of map
projections. This representation was clearly based on a model of a
physical telescope and how it imaged an observed region of the sky in
its focal plane.

While successfully accommodating the curvilinear nature of sky
coordinates, this FITS approach was still limited in many ways. In
essence, it defined a small set of functional forms (based on map
projections) through which pixel coordinates could be mapped on to
celestial coordinates and back again. However, if the actual
relationship between pixel coordinates and world coordinates didn't
correspond to one of these functional forms, then it wasn't possible
to use FITS to store the coordinate information\footnote{Unless the data was
first re-gridded into a form supported by FITS.}.

For instance, if astronomical instrumentation were to use a novel map
projection, if arbitrary instrumental distortions were present or if
the data were re-gridded into a non-physical space, then the FITS
approach would fail. It also had limited support for high-accuracy
astrometry, where the departure of the sky from a perfect sphere, for
a variety of reasons, has to be taken into account. In addition, there
are many other non-celestial world coordinate systems that one might
use (involving energy, velocity, time, frequency, etc.) that no
contemporary system could represent adequately.

Unfortunately, this list of limitations only scratches the surface of
the problem as it was perceived at the time. Other considerations,
such as the time-dependent relationship between non-inertial celestial
coordinate systems, the dependence of apparent positions on the
position and velocity of the observer (and also on the wavelength of
observation and atmospheric conditions) and periodic revisions to the
fundamental definitions of celestial coordinate and time systems would
all have to be accommodated, as would numerous other issues specific
to particular domains (celestial coordinates, time systems, radial
velocities, wavelength/energy, etc.). This was several years before the 
FITS community commenced work on what was eventually to become the current 
FITS-WCS standard.

\subsection{TRANSFORM}

In the late 1980s, no immediate and general solution to these problems
could be seen. Recognising the limitations in the FITS approach,
however, the Starlink Project decided to take a hard line and to omit
completely any component dedicated to world coordinate systems from
its new NDF data format. Instead, this \emph{astrometry extension}
(from which the name AST is derived) was to be added at a later date
when a suitable solution had been formulated.

This decision was undoubtedly strongly influenced by Patrick Wallace's
presence in the Project and the major work he had done on the SLALIB
library \citep[][\ascl{1403.025}]{1994ASPC...61..481W} to encapsulate best-practice in
astrometric calculations (and also in other domains such as time
systems). Discussion within the Project rapidly convinced us that if
we adopted the FITS approach as it existed at the time, we would cut
ourselves off from the proper rigorous treatment of astrometric data
that is needed for the highest accuracy.

Consequently, a pilot project was conducted to explore alternative
approaches. The most important limitation of the FITS approach was felt
to be the use of a fixed set of functional forms (map projections) each
of which was associated with a small fixed set of parameters. This
simplified storing the information in 80-character FITS \emph{header cards},
but clearly the set of functional forms that might ultimately be needed
was much larger than had been recognised. Adding new ones might become a
never-ending project and that, in turn, raised the prospect of
continually upgrading all software that had to read and process FITS
headers and handle coordinate systems.

The alternative approach that we explored was to write an expression
parser that would accept sets of arithmetic expressions similar to those
used in Fortran and C, along with the usual set of mathematical
functions. Together with a method of passing named parameter values into
these expressions, this greatly increased the set of functional forms
that could be represented. The expressions themselves (encoded as
character strings) and the associated parameter values could easily be
stored in astronomical datasets. Typically, one set of expressions would
relate pixel coordinates to world cordinates (e.g. sky coordinates) and
a second, optional, set would define the inverse transformation. The
expression syntax was powerful enough to represent a wide range of map
projections plus many other transformations into alternative world
coordinate systems.

A processing engine was also provided that could use the stored
expression data to transform actual coordinate values.

A library implementing this, called \textsc{transform}, was released
in 1989 \citep{SUN61,1989StarB...4....7L}. It stored its data (the
expressions and parameters) in Starlink's Hierarchical Data Format
\citep[HDS;][]{SUN92,SSN27} and was thus able to integrate with the
Starlink NDF data format to attach arbitrary world corrdinates to
gridded astronomical datasets.


\subsection{TRANSFORM Lessons}

Ultimately, \textsc{transform} turned out not to be a full solution to
the WCS problem and did not become part of the NDF data
format\footnote{Although it it was the precursor of the
  \texttt{MathMap} class in AST.}. It was, however, used for two
initially unforeseen purposes which turned out to be very significant:

\begin{enumerate}
\item Associating coordinate systems with plotting surfaces in a
  ``graphics database'' \citep[see e.g.,][]{SUN48}. This allowed
  plotting applications to store a coordinate system for (say) a graph
  plotted in logarithmic coordinates so that those coordinates could
  later be recovered from the position of a cursor. This demonstrated
  that plotting was a major application area for this type of
  technology, especially when using curvilinear coordinates such as
  Right Ascension and Declination which are notoriously difficult to
  handle properly with standard plotting software.

\item Transformation and combination of bulk image data using general
  arithmetic expressions (as an alternative to combining images using
  a manual sequence of add/subtract/multiply/divide and similar
  applications). This showed that (a) the approach could easily be
  efficient enough to handle large datasets and (b) the data values in
  an image were just another coordinate that could be transformed into
  different representations (logarithmic, different units, etc.) in
  much the same way as its axes.
\end{enumerate}

With these insights, it was clear that the ideas behind
\textsc{transform} had potential, but some serious deficiencies had
also emerged:

\begin{itemize}

\item Arithmetic expressions, while fairly general, could not easily
  cope with coordinate transformations that required iterative
  solution, nor with discontinuous transformations, nor with look-up
  tables or a variety of other computational techniques. While
  arithmetic expressions provided a valuable increase in the
  flexibility of coordinate transformations, clearly other classes
  were still needed.

\item It was a major problem for the average writer of astronomical
  software to formulate the required coordinate expressions correctly
  even when dealing with quite simple sky coordinate systems. The core
  of this issue is that celestial coordinate systems are rather
  complex and a good deal of specialist knowledge is needed to
  formulate even simple cases correctly. Clearly a better solution
  would be to encapsulate this knowledge in the WCS software and
  provide a simpler API that dealt only in high-level concepts.

\item For high accuracy work, further complex calculations
  arise. These are related, for example, to atmospheric refraction and
  special \& general relativistic effects (like the observer's motion
  and the sun's gravity).  These require the use of a dedicated
  library of astrometric functions and cannot in practice be handled
  by simple expressions. They also require additional data about the
  observing context (time, position, velocity, wavelength, etc.) and
  any practical solution must define how these are stored and
  processed.

\item \textsc{transform} had no ability to store additional
  information about data axes, such as labels and units.

\item It became clear that coordinate transformations frequently
  needed to be combined, for example by applying one transformation
  after another, and that this process was often inefficient. The key
  to better efficiency lay in knowing more about each transformation,
  like whether it was linear or had a variety of other
  properties. With this information it was possible to merge (or
  cancel out) consecutive transformations for better
  efficiency. \textsc{transform} had a rudimentary system for encoding
  this information, but it was not really up to the task.

\item Tying WCS software to a particular (Starlink) data system was a
  mistake and limited the uses to which it could be put. It would
  clearly be better if the data could be encoded (serialised) in
  alternative ways to make it data-system agnostic. The same
  agnosticism should also apply to other likely dependencies, like
  graphics systems and error reporting.  The ability to implement
  these services in alternative ways would be especially important
  when designing graphical user interfaces that processed WCS
  information.

\end{itemize}

\subsection{Developments in FITS WCS}

At about the same time, the wider FITS community also came to recognise
some of the limitations of WCS handling within FITS, and in 1992 work commenced 
on a new standard for storing WCS information within FITS files. However, 
in view of the ``once FITS, always FITS'' principle, that work consisted 
mainly in formalising and extending existing practices. So for instance, new 
keywords were defined to store the extra meta-data needed for a complete
description of a celestial coordinates system, and new projection types were 
added, but the basic model remained unchanged. The new standard still required 
that the transformation be split into three components applied in series; an 
affine transformation that converts pixel coordinates into \emph{intermediate 
world coordinates}, a spherical projection that converts these into \emph{native 
spherical coordinates}, and a spherical rotation that converts these into the
final world coordinate system.

In view of the decision to stay with this rigid and restrictive model,
and in view of expected length of time needed to agree a new standard\footnote{An
expectation that was justified when the stadard was finally published in 2002.},
the Starlink project decided in early 1996 to develope its own WCS system, informed 
by the earlier experiments with \textsc{transform}, rather than adopt the new FITS 
standard.

\subsection{AST Principles}

One of the first decisions was to
separate the representation of a coordinate system (that we called a
Frame) from the computational recipe that transforms between
coordinate systems (a Mapping). From the \textsc{transform} experience
we knew we would need multiple classes of both these data types, all
of which would need to support the same basic operations, but each
having its own specialisation. The correspondence with sub-classing in
object-oriented (OO) programming was irresistible and the decision to
use an OO design immediately followed.

This raised the issue of an implementation language. We planned to use
the SLALIB library for astrometric calculations\footnote{A later version 
of AST eventually replaced SLALIB with SOFA and PAL.}. This had been
developed with extreme portability in mind and had recently been
re-written in ANSI C. We didn't want to compromise this portability,
so decided also to work in strict ANSI C and to minimise software
dependencies as much as possible. This meant providing portable
interfaces to facilities that were intrinsically less portable, such
as data file access, plotting, error reporting, etc. and providing
simple implementations that users could re-write if necessary.

Deciding to write an OO system in a non-OO language took considerable
thought. We needed to provide a Fortran-callable interface but, at the
time, the portability of C++ code was quite limited if one needed to
call it from Fortran, so that route was unattractive. Eventually, we
were guided by the approach described by \citet{1992Holub} for
handling objects in C and were able to hide the detail from users
using pre-processor macros.

One consequence of this is that users cannot easily create new
sub-classes from AST objects without learning the internal conventions
that it uses. At the time, this was seen as something of an advantage.
The library is intended for data interchange and creating new
sub-classes would inevitably allow persistent objects to be created
that other users could not access. However, with hind-sight a more open
architecture may have encouraged involvement from a wider user-base.
\footnote{For Mappings, where this
  issue is most relevant, the problem has been mitigated in a
  controlled way by the IntraMap class that allows separately-compiled
  code to be imported into the library.}.

As noted previously, we wanted the AST API to deal in high-level
concepts and to hide as much specialist detail as possible from the
user. This principle arose from considering the complex calculations
involved in handling celestial coordinates and time systems. However,
we soon realised that two other areas were similarly complex and could
benefit from the same approach.

The first area was graphics. Plotting in curvilinear coordinates is a
complicated business if one wants to handle all the corner cases
correctly. Plotting and labelling celestial coordinate axes, for
example, presents many problems; especially near the poles of an all-sky
projection. It is made even harder if the projection contains
discontinuities. But the high-level concepts involved in such plotting
(coordinate systems and the mappings between them) are such a natural
fit with other AST concepts that it seemed obvious to implement a class
of coordinate system that is specialised for graphics. The high-level
operations it supports would then hide the details of the complex and
generalised plotting algorithms involved.

The second area is an aspect of data storage -- namely the handling of
FITS header cards. While the AST library could provide ways to
serialise its own data transparently, possibly in multiple ways, it
also needed to inter-operate with FITS. WCS data in FITS data files is
stored in a series of 80-character header cards and, over the years,
the number of different ways the information can be stored in these
headers has grown. The complexity involved is now considerable
\citep[see e.g.,][]{2015Thomas}. Again, detailed specialist knowledge
is needed to extract this information reliably and to write it back
(possibly modified) in a form that gives other FITS-handling software
a chance of using it while not conflicting with the many other FITS
headers typically present.

For a user of the AST library, we wanted this process of accessing FITS
headers to appear as much like a simple read/write operation as
possible, with all the implementation details hidden. This requirement
arose from more than simply ease-of-use. FITS header conventions (many
of them informal) are in constant flux and if these details are embedded
in applications programs, those programs must constantly receive
attention if they are to remain up to date. Embedding all these details
in the AST library allows the problem to be addressed in one place and
by someone with the necessary expertise.

FITS header handling has proved one of the most complex area to tame in AST.
But introducing the concept of a \emph{destructive read} (which reads WCS
data from FITS headers and simultaneously deletes the relevant headers)
has made it possible to write applications with very little code that
have completely general handling of FITS WCS headers.


\section{The AST Data Model}

\subsection{Key principles}

The basis of the AST data model is the distinction between a
\emph{transformation} and a \emph{coordinate system}.


Think in terms of Frames rather than axes. FITS-WCS tries to maintain
some sort of 1-to-1 correspondence between pixel axes and WCS axes,
and specifies the properties of each axis individually. But in general
there is no such correspondence (think of the case of a square image
centred on the north pole - which pixel axis corresponds to RA and
which to Dec?).

\subsection{Frames and Domains}

\subsubsection{What is a Domain?}

A physical space such as ``time'', ``the sky'', ``the EM spectrum'', ``the
focal plane'', ``a pixel array''. Points within such a space can in
general be described using any one of several coordinate systems
(e.g. the sky can be described using ICRS, Galactic, etc, the EM
spectrum can be described using freq, wavelength, etc). The ``Frame''
class represents a domain, and should encapsulate all the metadata
needed to transform a position between any pair of coordinate systems
that can be used to describe positions within its domain (in
retrospect, we should have named the class ``Domain'' rather than
``Frame''). Thus things like ``pixel size'' should \emph{not} be stored in a
Frame (Arnold), since it is a property of the relationship between two
Frames (a.k.a the Mapping) rather than of the Frame itself.

Basic Frame properties and methods:

\begin{itemize}
\item Sky, Time and Spec Frames
\item Compound Frames
\item Converting between Frames
\end{itemize}

\subsection{Mappings}

Mapping methods

Atomic Mappings

Compound Mappings (inc. SwitchMaps)

\subsubsection{Simplification}

There are a wide range of possible transformations that could
potentially be applied to a data set data during analysis. These
including simple things such as rotation, scaling, shear, etc., but
could in principle include more complex transformations such as
re-projection, dis-contiguous ``patchwork'' transformations, or even
transformation using a general algebraic expression.  A coordinate
handling system should make it possible for a user to apply an
arbitrary set of such transformations in series to a data set, without
losing track of the coordinates of each data point. With a
prescriptive scheme such as FITS-WCS this would require each
transformation to locate the appropriate component of the FITS-WCS
pixel to world coordinate mapping, and modify the corresponding
headers in a suitable way. This is often a difficult, if not
impossible, task. Within AST, the chaining of transformations is
accomplished simply by creating a Mapping that describes each new
transformation and concatenating it with the existing pixel to world
coordinate mapping.

However, by itself this can lead to the mapping becoming increasingly
complex as transformations are stacked on top of each other. This is
bad because it leads to
\begin{enumerate}
\item slower evaluation of the total transformation,
 \item less accurate evaluation of the total
transformation, and
\item more room being needed to store the total
transformation.
\end{enumerate}
To avoid this, the Mapping class provides a
``Simplify'' method that takes a potentially complex Mapping and
simplifies it as far as possible. Doing such simplification in a
general and effective manner is one of the most difficult challenges
faced by the AST model, but experience has shown that the current
scheme implemented in AST handles most cases sufficiently well. The
steps involved in simplification depend on the nature of the component
Mappings in the total Mapping. Each class of Mapping provides its own
rules that indicate when and how it can be simplified, or combined
with an adjacent Mapping in the chain. To illustrate the principle,
some of the simplest examples include,
\begin{enumerate}
 \item any Mapping can be combined with its own inverse to create a
   UnitMap,
\item UnitMaps can be removed entirely,
\item adjacent MatrixMaps can be combined using matrix
multiplication to create a single MatrixMap,
\item adjacent ShiftMaps can be combined to form a single ShiftMap.
\end{enumerate}

The whole simplification process is managed by the Simplify method of
the CmpMap class. It expands the compound Mapping into a list of
atomic Mappings to be applied in series or parallel, and then for each
Mapping in the list, invokes that Mappingâ€™s protected ``MapMerge''
method. This method is supplied with the entire list of atomic
Mappings, and determines if the nominated Mapping can be merged with
any of its neighbours. If so, a new list of Mappings is returned
containing the merged Mapping in place of the original mappings. Once
all atomic Mappings in the CmpMap have been checked in this way, the
same process is repeated again from the beginning in case any of the
changes that have been made to the list allow further simplifications
to be performed. This process is repeated until no further
simplifications occur.

\subsection{FrameSets}

\subsubsection{Base and Current Frames}

The ``base'' Frame represents the coordinate system in which axis values
are initially generated or obtained. For instance a cursor application
generates positions initially in graphics screen coordinates, and a
centroiding application generates them in pixel coordinates.  The
``current'' Frame represents the coordinate system in which positions
are required by subsequent user (code or human). This will often be
some form of WCS, such as (RA,Dec), but could potentially be any of
the Frames available in the FrameSet.

\subsubsection{Integrity restoration}

Changing a Frame to represent a different coordinate system should
cause the Mappings that connect it to the other Frames in the FrameSet
to be updated.

\subsubsection{Using a FrameSet to calibrate a data cube or table}

The base Frame represents grid coords, and the current Frame
represents WCS coords.  Explain about the usefulness of PIXEL versus
GRID coordinates.

\subsection{Regions}

These are the objects that contain actual axis values. They
encapsulate a Frame and set of positions defined within the
Frame. They can be transformed automatically into other Frames by
either changing the properties of the Frame or by using a Mapping to
map them into a new specified Frame.

The simplest subclass of Region is the PointList that represents one
or more positions within the Frame.  In practice, PointLists are
rarely used. This is because a typical application is usually
interested in positions that it has determined itself in some way, and
so can process them directly using Mappings without the need to create
an intermediate container object such as a PointList. Applications
that for instance displays the world coordinates of the cursor, or the
centroid position of an object, will usually obtain the axis values in
some ``base'' system such as graphics screen coordinates or pixel
coordinates, and will then transform them directly into the coordinate
system of interest using a suitable Mapping that it has obtained
previously. There is no need to first wrap the axis values in a
PointList, transform the PointList to a new coordinate system, and
then extract the coordinates from the transformed PointList. Doing so
can potentially introduces large overheads that can increase the
overall time taken to do the transformation.

Other subclasses include, Circle, Box, Ellipse, etc. Compound Regions
can be formed to represent the union or intersection of two
Regions. The Prism class allows Regions to be extruded into other
dimensions.

Regions can behave as either Mappings or Frames. When Used as a
Mapping, positions within the Region are left unchanged, and positions
outside the Region are set to a ``bad'' value.

Regions can contain a FrameSet in place of a Frame. In this case, the
shape and extent of the Region are defined within the base Frame of
the FrameSet, and the Region notionally represents a ``view'' of this
shape transformed into the current Frame of the FrameSet. For
instance, a ``Box'' could be created to represent the rectangular extent
of an image in pixel coordinates. Such a Box will contain a Frame
describing pixel coordinates, the pixel coordinates at the centre of
the image, and the extent of each dimension of the image (in
pixels). The Frame in this Box could be replaced by a FrameSet in
which the base Frame is again pixel coordinates, but the current Frame
is (RA,Dec). Internally, the Box still represents a rectangular area
in pixel coordinates, but is now viewed externally as the
corresponding curvilinear area in the (RA,Dec) Frame. When the Box is
used as a Mapping, it will first transform each position from (RA,Dec)
into pixel coordinates, and then test these transformed positions to
see if they are within the rectangular area of pixel coordinates
described by the Box.

\section{Fields of Application}



\subsection{Generalised Plotting}

\section{Things we would do differently now}

\begin{enumerate}

\item Be clearer about the distinction between a coordinate system and
  a domain. Coordinate systems are mathematical abstractions of
  various types (Cartesian, polar, etc). You use a coordinate system
  to describe a position within a physical space (domain). In this
  sense a domain can encapsulate several alternative coordinate
  systems, any of which can be used to describe positions in the
  domain.

\item Have a specific sub-class of Frame to describe a pixel array ( a
  PixelFrame), allowing System=GRID or System=PIXEL.

\item Use degrees instead of radians for sky axes.

\item The restriction that Mappings can only transform doubles may be
  a problem for time axes (but this is an issue with the
  implementation rather than the model).

\item Make it more modular. Some sort of facility for optional
  extensions or plug-ins, so that the thing does not become such a
  huge monolithic lump.

\end{enumerate}

\section{The AST library}

The AST library has been developed over a number of years
\citep{1998ASPC..145...41W,2000ASPC..216..506W,2001ASPC..238..129B,2004ASPC..314..412B,2008ASPC..394..635B,2010ASPC..434..213B,2012ASPC..461..825B}
  and is written in C with no dependencies. It includes code from
  WCSLIB \citep[][\ascl{1108.003}]{2006ASPC..351..591C}, PAL \citep{2013ASPC..475..307J}
  and SOFA \citep[][\ascl{1403.026}]{2011SchpJ...611404H} but does not depend on those
  libraries. There are language bindings for Fortran, Java, Perl and
  Python.

\section{Acknowledgements}

The Starlink software is currently maintained by the Joint Astronomy
Centre, Hawaii with support from the UK Science and Technology
Facilities Council. The source code is open-source using the Lesser
Gnu Public License and is available
online\footnote{\url{https://github.com/Starlink/starlink}}.


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% References
%%
%% Following citation commands can be used in the body text:
%%
%%  \citet{key}  ==>>  Jones et al. (1990)
%%  \citep{key}  ==>>  (Jones et al., 1990)
%%
%% Multiple citations as normal:
%% \citep{key1,key2}         ==>> (Jones et al., 1990; Smith, 1989)
%%                            or  (Jones et al., 1990, 1991)
%%                            or  (Jones et al., 1990a,b)
%% \cite{key} is the equivalent of \citet{key} in author-year mode
%%
%% Full author lists may be forced with \citet* or \citep*, e.g.
%%   \citep*{key}            ==>> (Jones, Baker, and Williams, 1990)
%%
%% Optional notes as:
%%   \citep[chap. 2]{key}    ==>> (Jones et al., 1990, chap. 2)
%%   \citep[e.g.,][]{key}    ==>> (e.g., Jones et al., 1990)
%%   \citep[see][pg. 34]{key}==>> (see Jones et al., 1990, pg. 34)
%%  (Note: in standard LaTeX, only one note is allowed, after the ref.
%%   Here, one note is like the standard, two make pre- and post-notes.)
%%
%%   \citealt{key}          ==>> Jones et al. 1990
%%   \citealt*{key}         ==>> Jones, Baker, and Williams 1990
%%   \citealp{key}          ==>> Jones et al., 1990
%%   \citealp*{key}         ==>> Jones, Baker, and Williams, 1990
%%
%% Additional citation possibilities
%%   \citeauthor{key}       ==>> Jones et al.
%%   \citeauthor*{key}      ==>> Jones, Baker, and Williams
%%   \citeyear{key}         ==>> 1990
%%   \citeyearpar{key}      ==>> (1990)
%%   \citetext{priv. comm.} ==>> (priv. comm.)
%%   \citenum{key}          ==>> 11 [non-superscripted]
%% Note: full author lists depends on whether the bib style supports them;
%%       if not, the abbreviated list is printed even when full requested.
%%
%% For names like della Robbia at the start of a sentence, use
%%   \Citet{dRob98}         ==>> Della Robbia (1998)
%%   \Citep{dRob98}         ==>> (Della Robbia, 1998)
%%   \Citeauthor{dRob98}    ==>> Della Robbia


%% References with bibTeX database:

\bibliographystyle{model2-names-astronomy}
\bibliography{acast}

%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use model2-names.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have one of the following forms:
%%   \bibitem[Jones et al.(1990)]{key}...
%%   \bibitem[Jones et al.(1990)Jones, Baker, and Williams]{key}...
%%   \bibitem[Jones et al., 1990]{key}...
%%   \bibitem[\protect\citeauthoryear{Jones, Baker, and Williams}{Jones
%%       et al.}{1990}]{key}...
%%   \bibitem[\protect\citeauthoryear{Jones et al.}{1990}]{key}...
%%   \bibitem[\protect\astroncite{Jones et al.}{1990}]{key}...
%%   \bibitem[\protect\citename{Jones et al., }1990]{key}...
%%   \harvarditem[Jones et al.]{Jones, Baker, and Williams}{1990}{key}...
%%

% \bibitem[ ()]{}

% \end{thebibliography}

\end{document}

%%
%% End of file `elsarticle-template-2-harv.tex'.
